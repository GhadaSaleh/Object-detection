{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::910340444796:role/service-role/AmazonSageMaker-ExecutionRole-20230404T010108\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "        'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://my-object-detection-project/logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad5ac8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'docker/models' already exists and is not an empty directory.\n",
      "bash: line 6: !sh: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# clone the repo and get the scripts\n",
    "git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# get model_main and exporter_main files from TF2 Objecimage_name = 'tf2-object-detection'\n",
    "!sh ./docker/build_and_push.sh $image_namet Detection GitHub repository\n",
    "cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dab3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and push the docker image. This code can be commented after being ran once.\n",
    "# This will take around 10 mins.\n",
    "#image_name = 'tf2-object-detection'\n",
    "#!sh ./docker/build_and_push.sh $image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910340444796.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20230404231810\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be ajusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4b1d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘source_dir/checkpoint’: File exists\n",
      "--2023-04-05 03:23:54--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.31.128, 2607:f8b0:4004:c17::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.31.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘/tmp/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 17.7M 1s\n",
      "    50K .......... .......... .......... .......... ..........  0% 32.5M 1s\n",
      "   100K .......... .......... .......... .......... ..........  0% 32.4M 1s\n",
      "   150K .......... .......... .......... .......... ..........  0% 88.6M 1s\n",
      "   200K .......... .......... .......... .......... ..........  1%  134M 1s\n",
      "   250K .......... .......... .......... .......... ..........  1% 70.3M 0s\n",
      "   300K .......... .......... .......... .......... ..........  1%  116M 0s\n",
      "   350K .......... .......... .......... .......... ..........  1%  174M 0s\n",
      "   400K .......... .......... .......... .......... ..........  2%  160M 0s\n",
      "   450K .......... .......... .......... .......... ..........  2%  122M 0s\n",
      "   500K .......... .......... .......... .......... ..........  2%  133M 0s\n",
      "   550K .......... .......... .......... .......... ..........  2%  119M 0s\n",
      "   600K .......... .......... .......... .......... ..........  3%  126M 0s\n",
      "   650K .......... .......... .......... .......... ..........  3%  112M 0s\n",
      "   700K .......... .......... .......... .......... ..........  3%  119M 0s\n",
      "   750K .......... .......... .......... .......... ..........  3%  112M 0s\n",
      "   800K .......... .......... .......... .......... ..........  4% 98.7M 0s\n",
      "   850K .......... .......... .......... .......... ..........  4% 99.3M 0s\n",
      "   900K .......... .......... .......... .......... ..........  4%  290M 0s\n",
      "   950K .......... .......... .......... .......... ..........  4%  269M 0s\n",
      "  1000K .......... .......... .......... .......... ..........  5%  308M 0s\n",
      "  1050K .......... .......... .......... .......... ..........  5%  319M 0s\n",
      "  1100K .......... .......... .......... .......... ..........  5%  291M 0s\n",
      "  1150K .......... .......... .......... .......... ..........  5%  277M 0s\n",
      "  1200K .......... .......... .......... .......... ..........  6%  315M 0s\n",
      "  1250K .......... .......... .......... .......... ..........  6%  314M 0s\n",
      "  1300K .......... .......... .......... .......... ..........  6%  302M 0s\n",
      "  1350K .......... .......... .......... .......... ..........  6%  257M 0s\n",
      "  1400K .......... .......... .......... .......... ..........  7%  325M 0s\n",
      "  1450K .......... .......... .......... .......... ..........  7%  302M 0s\n",
      "  1500K .......... .......... .......... .......... ..........  7%  316M 0s\n",
      "  1550K .......... .......... .......... .......... ..........  7%  264M 0s\n",
      "  1600K .......... .......... .......... .......... ..........  8%  317M 0s\n",
      "  1650K .......... .......... .......... .......... ..........  8%  321M 0s\n",
      "  1700K .......... .......... .......... .......... ..........  8%  321M 0s\n",
      "  1750K .......... .......... .......... .......... ..........  8%  275M 0s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  320M 0s\n",
      "  1850K .......... .......... .......... .......... ..........  9%  321M 0s\n",
      "  1900K .......... .......... .......... .......... ..........  9%  303M 0s\n",
      "  1950K .......... .......... .......... .......... ..........  9%  238M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 10% 9.71M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 10% 95.2M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 10%  127M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 10%  139M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 11%  105M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 11%  241M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 11%  160M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 11%  324M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  196M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 12%  117M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 12%  115M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 12%  127M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 13%  107M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 13%  108M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 13%  163M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 13%  159M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 14%  131M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 14%  190M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 14%  168M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 14%  325M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 15%  283M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 15%  327M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 15%  290M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 15%  304M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 16%  271M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 16%  316M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 16%  326M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 16%  325M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 17%  269M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 17%  331M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 17%  328M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 17%  307M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 18%  282M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 18%  325M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 18%  328M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 18%  312M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 19%  286M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 19%  312M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 19%  312M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 19%  316M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 20%  273M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 20% 1.27M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 20% 96.2M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 20%  220M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 21%  171M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 21%  124M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 21%  321M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 21%  244M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 22%  105M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 22%  213M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 22%  103M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 22%  112M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 23%  149M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 23%  130M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 23%  134M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 23%  202M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 24% 98.4M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 24%  318M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 24%  244M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 24%  185M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 25%  159M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 25%  147M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 25%  124M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 25%  136M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 26% 75.2M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 26%  112M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 26%  178M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 26%  180M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 27%  208M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 27%  137M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 27%  133M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 27%  165M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 28%  116M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 28%  131M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 28%  151M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 28%  215M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 29%  300M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 29%  317M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 29%  236M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 29%  372M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 30%  262M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 30%  202M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 30%  212M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 30%  171M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 31%  161M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 31%  240M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 31%  334M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 31%  476M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 32%  221M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 32%  209M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 32%  243M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 32%  198M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 33%  225M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 33%  281M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 33%  283M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 33%  263M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 34%  251M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 34%  289M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 34%  261M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 34%  256M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 35%  252M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 35%  266M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 35%  287M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 35%  301M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 36%  206M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 36%  271M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 36%  294M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 36%  284M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 37%  277M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 37%  315M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 37%  326M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 37%  326M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 38%  287M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 38%  211M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 38%  283M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 38%  281M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 39%  254M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 39%  263M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 39%  287M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 39%  286M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 40%  224M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 40%  274M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 40%  249M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 40%  275M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 41%  250M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 41%  230M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 41%  283M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 41%  278M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 42%  245M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 42%  245M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 42%  296M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 42%  273M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 43%  242M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 43%  321M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 43%  305M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 43%  218M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 44%  233M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 44%  249M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 44%  277M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 44%  253M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 45%  232M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 45%  264M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 45%  258M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 45%  282M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 46%  238M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 46%  302M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 46%  292M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 46%  277M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 47%  242M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 47%  282M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 47%  294M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 47%  297M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 48%  236M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 48%  251M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 48%  242M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 48%  280M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 49%  206M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 49%  267M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 49%  273M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 49%  297M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 50%  236M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 50%  271M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 50%  295M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 50%  281M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 51%  211M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 51%  277M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 51%  260M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 51%  241M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 52%  229M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 52%  248M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 52%  260M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 52%  289M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 53%  245M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 53%  250M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 53%  259M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 53%  285M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 54%  194M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 54%  232M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 54%  269M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 54%  287M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 55%  195M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 55%  281M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 55%  239M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 55%  270M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 56%  253M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 56%  241M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 56%  264M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 56%  273M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 57%  276M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 57%  229M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 57%  350M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 57%  332M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 58%  273M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 58%  344M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 58%  322M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 58%  317M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 59%  240M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 59%  258M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 59%  287M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 59%  252M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 60%  240M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 60%  257M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 60%  307M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 60%  302M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 61%  248M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 61%  264M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 61%  290M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 61%  282M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 62%  234M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 62%  288M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 62%  280M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 62%  300M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 63%  229M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 63%  279M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 63%  292M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 63%  300M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 64%  240M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 64%  294M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 64%  292M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 64%  249M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 65%  253M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 65%  220M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 65%  263M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 65%  309M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 66%  251M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 66%  295M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 66%  262M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 66%  266M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 67%  245M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 67%  252M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 67%  282M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 67%  305M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 68%  237M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 68%  282M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 68%  244M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 68%  269M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 69%  231M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 69%  304M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 69%  280M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 69%  251M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 70%  229M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 70%  287M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 70%  233M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 70%  247M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 71%  231M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 71%  289M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 71%  290M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 71%  253M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 72%  243M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 72%  267M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 72%  270M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 72%  289M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 73%  247M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 73%  323M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 73%  260M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 73%  266M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 74%  225M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 74%  244M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 74%  289M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 74%  270M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 75%  258M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 75%  271M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 75%  254M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 75%  286M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 76%  221M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 76%  295M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 76%  288M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 76%  303M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 77%  261M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 77%  277M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 77%  258M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 77%  309M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 78%  260M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 78%  248M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 78%  263M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 78%  314M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 79%  245M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 79%  263M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 79%  261M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 79%  272M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 80%  247M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 80%  261M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 80%  284M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 80%  301M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 81%  275M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 81%  324M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 81%  280M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 81%  291M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 82%  274M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 82%  300M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 82%  307M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 82%  323M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 83%  277M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 83%  296M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 83%  320M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 83%  304M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 84%  250M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 84%  291M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 84%  316M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 84%  320M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 85%  264M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 85%  318M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 85%  297M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 85%  295M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 86%  267M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 86%  316M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 86%  321M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 86%  325M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 87%  269M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 87%  308M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 87%  275M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 87%  317M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 88%  281M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 88%  304M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 88%  321M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 88%  299M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 89%  263M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 89%  327M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 89%  308M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 89%  325M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 90%  285M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 90%  324M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 90%  290M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 90%  310M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 91%  263M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 91%  282M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 91%  303M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 91%  320M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 92%  278M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 92%  298M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 92%  324M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 92%  326M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 93%  245M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 93%  329M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 93%  296M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 93%  283M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 94%  272M 0s\n",
      " 18850K .......... .......... .......... .......... .......... 94%  290M 0s\n",
      " 18900K .......... .......... .......... .......... .......... 94%  291M 0s\n",
      " 18950K .......... .......... .......... .......... .......... 94%  319M 0s\n",
      " 19000K .......... .......... .......... .......... .......... 95%  275M 0s\n",
      " 19050K .......... .......... .......... .......... .......... 95%  327M 0s\n",
      " 19100K .......... .......... .......... .......... .......... 95%  307M 0s\n",
      " 19150K .......... .......... .......... .......... .......... 95%  331M 0s\n",
      " 19200K .......... .......... .......... .......... .......... 96%  261M 0s\n",
      " 19250K .......... .......... .......... .......... .......... 96%  327M 0s\n",
      " 19300K .......... .......... .......... .......... .......... 96%  310M 0s\n",
      " 19350K .......... .......... .......... .......... .......... 96%  322M 0s\n",
      " 19400K .......... .......... .......... .......... .......... 97%  283M 0s\n",
      " 19450K .......... .......... .......... .......... .......... 97%  292M 0s\n",
      " 19500K .......... .......... .......... .......... .......... 97%  325M 0s\n",
      " 19550K .......... .......... .......... .......... .......... 97%  310M 0s\n",
      " 19600K .......... .......... .......... .......... .......... 98%  282M 0s\n",
      " 19650K .......... .......... .......... .......... .......... 98%  316M 0s\n",
      " 19700K .......... .......... .......... .......... .......... 98%  311M 0s\n",
      " 19750K .......... .......... .......... .......... .......... 98%  331M 0s\n",
      " 19800K .......... .......... .......... .......... .......... 99%  281M 0s\n",
      " 19850K .......... .......... .......... .......... .......... 99%  317M 0s\n",
      " 19900K .......... .......... .......... .......... .......... 99%  317M 0s\n",
      " 19950K .......... .......... .......... .......... .......... 99%  286M 0s\n",
      " 20000K .......... .......... .......... .......              100%  281M=0.1s\n",
      "\n",
      "2023-04-05 03:23:54 (148 MB/s) - ‘/tmp/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "wget -O /tmp/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "tar -zxvf /tmp/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\":\"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    #instance_type='ml.trn1.2xlarge',\n",
    "    instance_type='ml.trn1.2xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0608c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf2-object-detection-2023-04-05-03-47-01-765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-05 03:47:04 Starting - Starting the training job...\n",
      "2023-04-05 03:47:18 Starting - Preparing the instances for training...\n",
      "2023-04-05 03:48:06 Downloading - Downloading input data...\n",
      "2023-04-05 03:48:26 Training - Downloading the training image............\n",
      "2023-04-05 03:50:42 Training - Training image download completed. Training in progress.....\u001b[34m2023-04-05 03:51:11,235 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,237 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,248 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,250 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,261 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,263 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,272 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.trn1.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.trn1.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2023-04-05-03-47-01-765\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-910340444796/tf2-object-detection-2023-04-05-03-47-01-765/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.trn1.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.trn1.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.trn1.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.trn1.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.trn1.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.trn1.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-910340444796/tf2-object-detection-2023-04-05-03-47-01-765/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.trn1.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.trn1.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"tf2-object-detection-2023-04-05-03-47-01-765\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-910340444796/tf2-object-detection-2023-04-05-03-47-01-765/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.trn1.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.trn1.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2023-04-05 03:51:11,273 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \u001b[0m\n",
      "\u001b[34mSome things might work, some things might not.\u001b[0m\n",
      "\u001b[34mIf you were to encounter a bug, do not file an issue.\u001b[0m\n",
      "\u001b[34mIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \u001b[0m\n",
      "\u001b[34mYou can find the compatibility matrix in TensorFlow Addon's readme:\u001b[0m\n",
      "\u001b[34mhttps://github.com/tensorflow/addons\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\u001b[0m\n",
      "\u001b[34mW0405 03:51:16.351219 140711772489536 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\u001b[0m\n",
      "\u001b[34mI0405 03:51:16.368907 140711772489536 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI0405 03:51:16.371805 140711772489536 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0405 03:51:16.371906 140711772489536 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW0405 03:51:16.394230 140711772489536 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0405 03:51:16.400654 140711772489536 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0405 03:51:16.401615 140711772489536 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI0405 03:51:16.401690 140711772489536 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0405 03:51:16.408916 140711772489536 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0405 03:51:16.423603 140711772489536 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0405 03:51:22.137254 140711772489536 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mW0405 03:51:24.570353 140711772489536 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0405 03:51:25.796245 140711772489536 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34mW0405 03:51:27.675414 140711772489536 module_wrapper.py:149] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0405 03:51:32.472464 140707371132672 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 03:51:39.469773 140707371132672 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW0405 03:51:44.943434 140706406459136 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI0405 03:51:45.889540 140706406459136 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 03:51:50.528438 140706406459136 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 03:51:54.931868 140706406459136 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 03:51:59.300922 140706406459136 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 1.852s\u001b[0m\n",
      "\u001b[34mI0405 03:54:49.812937 140711772489536 model_lib_v2.py:705] Step 100 per-step time 1.852s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2931607,\n",
      " 'Loss/localization_loss': 0.46615797,\n",
      " 'Loss/regularization_loss': 0.15145649,\n",
      " 'Loss/total_loss': 0.9107752,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mI0405 03:54:49.813285 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.2931607,\n",
      " 'Loss/localization_loss': 0.46615797,\n",
      " 'Loss/regularization_loss': 0.15145649,\n",
      " 'Loss/total_loss': 0.9107752,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 1.612s\u001b[0m\n",
      "\u001b[34mI0405 03:57:30.990278 140711772489536 model_lib_v2.py:705] Step 200 per-step time 1.612s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29356188,\n",
      " 'Loss/localization_loss': 0.3335907,\n",
      " 'Loss/regularization_loss': 0.15143824,\n",
      " 'Loss/total_loss': 0.7785908,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mI0405 03:57:30.990549 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.29356188,\n",
      " 'Loss/localization_loss': 0.3335907,\n",
      " 'Loss/regularization_loss': 0.15143824,\n",
      " 'Loss/total_loss': 0.7785908,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 1.615s\u001b[0m\n",
      "\u001b[34mI0405 04:00:12.476747 140711772489536 model_lib_v2.py:705] Step 300 per-step time 1.615s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2276053,\n",
      " 'Loss/localization_loss': 0.3101274,\n",
      " 'Loss/regularization_loss': 0.15135546,\n",
      " 'Loss/total_loss': 0.68908817,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mI0405 04:00:12.477030 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.2276053,\n",
      " 'Loss/localization_loss': 0.3101274,\n",
      " 'Loss/regularization_loss': 0.15135546,\n",
      " 'Loss/total_loss': 0.68908817,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 1.616s\u001b[0m\n",
      "\u001b[34mI0405 04:02:54.078899 140711772489536 model_lib_v2.py:705] Step 400 per-step time 1.616s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.23278339,\n",
      " 'Loss/localization_loss': 0.33747798,\n",
      " 'Loss/regularization_loss': 0.15127218,\n",
      " 'Loss/total_loss': 0.72153354,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mI0405 04:02:54.079164 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.23278339,\n",
      " 'Loss/localization_loss': 0.33747798,\n",
      " 'Loss/regularization_loss': 0.15127218,\n",
      " 'Loss/total_loss': 0.72153354,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 1.631s\u001b[0m\n",
      "\u001b[34mI0405 04:05:37.201915 140711772489536 model_lib_v2.py:705] Step 500 per-step time 1.631s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20498832,\n",
      " 'Loss/localization_loss': 0.26565593,\n",
      " 'Loss/regularization_loss': 0.1511865,\n",
      " 'Loss/total_loss': 0.62183076,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mI0405 04:05:37.202187 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.20498832,\n",
      " 'Loss/localization_loss': 0.26565593,\n",
      " 'Loss/regularization_loss': 0.1511865,\n",
      " 'Loss/total_loss': 0.62183076,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 1.663s\u001b[0m\n",
      "\u001b[34mI0405 04:08:23.518617 140711772489536 model_lib_v2.py:705] Step 600 per-step time 1.663s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26366627,\n",
      " 'Loss/localization_loss': 0.36192787,\n",
      " 'Loss/regularization_loss': 0.15115318,\n",
      " 'Loss/total_loss': 0.77674735,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mI0405 04:08:23.518877 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.26366627,\n",
      " 'Loss/localization_loss': 0.36192787,\n",
      " 'Loss/regularization_loss': 0.15115318,\n",
      " 'Loss/total_loss': 0.77674735,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 1.754s\u001b[0m\n",
      "\u001b[34mI0405 04:11:18.881551 140711772489536 model_lib_v2.py:705] Step 700 per-step time 1.754s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24270833,\n",
      " 'Loss/localization_loss': 0.32612848,\n",
      " 'Loss/regularization_loss': 0.15110643,\n",
      " 'Loss/total_loss': 0.7199432,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mI0405 04:11:18.881845 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.24270833,\n",
      " 'Loss/localization_loss': 0.32612848,\n",
      " 'Loss/regularization_loss': 0.15110643,\n",
      " 'Loss/total_loss': 0.7199432,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 1.752s\u001b[0m\n",
      "\u001b[34mI0405 04:14:14.101237 140711772489536 model_lib_v2.py:705] Step 800 per-step time 1.752s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21101665,\n",
      " 'Loss/localization_loss': 0.30405554,\n",
      " 'Loss/regularization_loss': 0.15112844,\n",
      " 'Loss/total_loss': 0.66620064,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mI0405 04:14:14.101507 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.21101665,\n",
      " 'Loss/localization_loss': 0.30405554,\n",
      " 'Loss/regularization_loss': 0.15112844,\n",
      " 'Loss/total_loss': 0.66620064,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 1.753s\u001b[0m\n",
      "\u001b[34mI0405 04:17:09.359264 140711772489536 model_lib_v2.py:705] Step 900 per-step time 1.753s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2468688,\n",
      " 'Loss/localization_loss': 0.37830508,\n",
      " 'Loss/regularization_loss': 0.15114552,\n",
      " 'Loss/total_loss': 0.7763194,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mI0405 04:17:09.359549 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.2468688,\n",
      " 'Loss/localization_loss': 0.37830508,\n",
      " 'Loss/regularization_loss': 0.15114552,\n",
      " 'Loss/total_loss': 0.7763194,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 1.752s\u001b[0m\n",
      "\u001b[34mI0405 04:20:04.587953 140711772489536 model_lib_v2.py:705] Step 1000 per-step time 1.752s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2442066,\n",
      " 'Loss/localization_loss': 0.3401417,\n",
      " 'Loss/regularization_loss': 0.15105256,\n",
      " 'Loss/total_loss': 0.7354009,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mI0405 04:20:04.588227 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.2442066,\n",
      " 'Loss/localization_loss': 0.3401417,\n",
      " 'Loss/regularization_loss': 0.15105256,\n",
      " 'Loss/total_loss': 0.7354009,\n",
      " 'learning_rate': 0.08}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 1.760s\u001b[0m\n",
      "\u001b[34mI0405 04:23:00.610111 140711772489536 model_lib_v2.py:705] Step 1100 per-step time 1.760s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24700218,\n",
      " 'Loss/localization_loss': 0.30025256,\n",
      " 'Loss/regularization_loss': 0.15098786,\n",
      " 'Loss/total_loss': 0.6982426,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mI0405 04:23:00.610412 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.24700218,\n",
      " 'Loss/localization_loss': 0.30025256,\n",
      " 'Loss/regularization_loss': 0.15098786,\n",
      " 'Loss/total_loss': 0.6982426,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 1.751s\u001b[0m\n",
      "\u001b[34mI0405 04:25:55.730201 140711772489536 model_lib_v2.py:705] Step 1200 per-step time 1.751s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.1648966,\n",
      " 'Loss/localization_loss': 0.24811147,\n",
      " 'Loss/regularization_loss': 0.15086247,\n",
      " 'Loss/total_loss': 0.56387055,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mI0405 04:25:55.730523 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.1648966,\n",
      " 'Loss/localization_loss': 0.24811147,\n",
      " 'Loss/regularization_loss': 0.15086247,\n",
      " 'Loss/total_loss': 0.56387055,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 1.754s\u001b[0m\n",
      "\u001b[34mI0405 04:28:51.124569 140711772489536 model_lib_v2.py:705] Step 1300 per-step time 1.754s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19284807,\n",
      " 'Loss/localization_loss': 0.26756263,\n",
      " 'Loss/regularization_loss': 0.1505861,\n",
      " 'Loss/total_loss': 0.6109968,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mI0405 04:28:51.124831 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.19284807,\n",
      " 'Loss/localization_loss': 0.26756263,\n",
      " 'Loss/regularization_loss': 0.1505861,\n",
      " 'Loss/total_loss': 0.6109968,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 1.753s\u001b[0m\n",
      "\u001b[34mI0405 04:31:46.376377 140711772489536 model_lib_v2.py:705] Step 1400 per-step time 1.753s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18979016,\n",
      " 'Loss/localization_loss': 0.2937953,\n",
      " 'Loss/regularization_loss': 0.15024672,\n",
      " 'Loss/total_loss': 0.63383216,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mI0405 04:31:46.376668 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.18979016,\n",
      " 'Loss/localization_loss': 0.2937953,\n",
      " 'Loss/regularization_loss': 0.15024672,\n",
      " 'Loss/total_loss': 0.63383216,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 1.749s\u001b[0m\n",
      "\u001b[34mI0405 04:34:41.269042 140711772489536 model_lib_v2.py:705] Step 1500 per-step time 1.749s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18510032,\n",
      " 'Loss/localization_loss': 0.24825403,\n",
      " 'Loss/regularization_loss': 0.15000384,\n",
      " 'Loss/total_loss': 0.58335817,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mI0405 04:34:41.269293 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.18510032,\n",
      " 'Loss/localization_loss': 0.24825403,\n",
      " 'Loss/regularization_loss': 0.15000384,\n",
      " 'Loss/total_loss': 0.58335817,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 1.750s\u001b[0m\n",
      "\u001b[34mI0405 04:37:36.292136 140711772489536 model_lib_v2.py:705] Step 1600 per-step time 1.750s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19780359,\n",
      " 'Loss/localization_loss': 0.26839888,\n",
      " 'Loss/regularization_loss': 0.14982706,\n",
      " 'Loss/total_loss': 0.6160295,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mI0405 04:37:36.292412 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.19780359,\n",
      " 'Loss/localization_loss': 0.26839888,\n",
      " 'Loss/regularization_loss': 0.14982706,\n",
      " 'Loss/total_loss': 0.6160295,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 1.752s\u001b[0m\n",
      "\u001b[34mI0405 04:40:31.491632 140711772489536 model_lib_v2.py:705] Step 1700 per-step time 1.752s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18535028,\n",
      " 'Loss/localization_loss': 0.21890393,\n",
      " 'Loss/regularization_loss': 0.14954752,\n",
      " 'Loss/total_loss': 0.5538018,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mI0405 04:40:31.491944 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.18535028,\n",
      " 'Loss/localization_loss': 0.21890393,\n",
      " 'Loss/regularization_loss': 0.14954752,\n",
      " 'Loss/total_loss': 0.5538018,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 1.751s\u001b[0m\n",
      "\u001b[34mI0405 04:43:26.610819 140711772489536 model_lib_v2.py:705] Step 1800 per-step time 1.751s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20640634,\n",
      " 'Loss/localization_loss': 0.31866688,\n",
      " 'Loss/regularization_loss': 0.14921966,\n",
      " 'Loss/total_loss': 0.67429286,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mI0405 04:43:26.611101 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.20640634,\n",
      " 'Loss/localization_loss': 0.31866688,\n",
      " 'Loss/regularization_loss': 0.14921966,\n",
      " 'Loss/total_loss': 0.67429286,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 1.772s\u001b[0m\n",
      "\u001b[34mI0405 04:46:23.787839 140711772489536 model_lib_v2.py:705] Step 1900 per-step time 1.772s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2012668,\n",
      " 'Loss/localization_loss': 0.23674169,\n",
      " 'Loss/regularization_loss': 0.14890158,\n",
      " 'Loss/total_loss': 0.58691007,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mI0405 04:46:23.788118 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.2012668,\n",
      " 'Loss/localization_loss': 0.23674169,\n",
      " 'Loss/regularization_loss': 0.14890158,\n",
      " 'Loss/total_loss': 0.58691007,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 1.749s\u001b[0m\n",
      "\u001b[34mI0405 04:49:18.655336 140711772489536 model_lib_v2.py:705] Step 2000 per-step time 1.749s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.1995995,\n",
      " 'Loss/localization_loss': 0.28235617,\n",
      " 'Loss/regularization_loss': 0.14856699,\n",
      " 'Loss/total_loss': 0.63052267,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34mI0405 04:49:18.655610 140711772489536 model_lib_v2.py:708] {'Loss/classification_loss': 0.1995995,\n",
      " 'Loss/localization_loss': 0.28235617,\n",
      " 'Loss/regularization_loss': 0.14856699,\n",
      " 'Loss/total_loss': 0.63052267,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \u001b[0m\n",
      "\u001b[34mSome things might work, some things might not.\u001b[0m\n",
      "\u001b[34mIf you were to encounter a bug, do not file an issue.\u001b[0m\n",
      "\u001b[34mIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \u001b[0m\n",
      "\u001b[34mYou can find the compatibility matrix in TensorFlow Addon's readme:\u001b[0m\n",
      "\u001b[34mhttps://github.com/tensorflow/addons\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW0405 04:49:24.594931 140241026598720 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI0405 04:49:24.595099 140241026598720 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0405 04:49:24.595159 140241026598720 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI0405 04:49:24.595226 140241026598720 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW0405 04:49:24.595312 140241026598720 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0405 04:49:24.651833 140241026598720 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI0405 04:49:24.652801 140241026598720 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI0405 04:49:24.652904 140241026598720 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW0405 04:49:24.652953 140241026598720 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW0405 04:49:24.657040 140241026598720 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0405 04:49:24.659344 140241026598720 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0405 04:49:24.675716 140241026598720 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0405 04:49:28.246154 140241026598720 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0405 04:49:29.256839 140241026598720 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34mW0405 04:49:31.693913 140241026598720 module_wrapper.py:149] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0405 04:49:31.694293 140241026598720 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI0405 04:49:31.694818 140241026598720 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI0405 04:49:36.623837 140241026598720 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 04:49:47.478106 140241026598720 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0405 04:49:50.879226 140241026598720 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0405 04:49:50.895644 140241026598720 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW0405 04:49:51.021994 140241026598720 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0405 04:50:00.914770 140241026598720 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0405 04:50:07.997468 140241026598720 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI0405 04:50:12.212976 140241026598720 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0405 04:50:12.218300 140241026598720 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mI0405 04:50:12.231396 140241026598720 coco_tools.py:138] DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.039235 140241026598720 model_lib_v2.py:1015] Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.102228\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.050092 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.102228\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.224864\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.050940 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.224864\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.085147\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.051532 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.085147\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.040451\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.052060 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.040451\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.358189\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.052572 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.358189\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.478445\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.053094 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.478445\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.025000\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.053586 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.025000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.107004\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.054074 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.107004\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.158670\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.054559 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.158670\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.099854\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.055081 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.099854\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.453201\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.055573 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.453201\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.505894\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.056108 140241026598720 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.505894\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.416217\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.056533 140241026598720 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.416217\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.394773\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.056990 140241026598720 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.394773\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.148565\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.057430 140241026598720 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.148565\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.959555\u001b[0m\n",
      "\u001b[34mI0405 04:50:20.057842 140241026598720 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.959555\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI0405 04:54:31.794996 140241026598720 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI0405 04:54:40.809061 140241026598720 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=7.54s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \u001b[0m\n",
      "\u001b[34mSome things might work, some things might not.\u001b[0m\n",
      "\u001b[34mIf you were to encounter a bug, do not file an issue.\u001b[0m\n",
      "\u001b[34mIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \u001b[0m\n",
      "\u001b[34mYou can find the compatibility matrix in TensorFlow Addon's readme:\u001b[0m\n",
      "\u001b[34mhttps://github.com/tensorflow/addons\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW0405 04:54:45.073457 140610458367808 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mI0405 04:54:48.736579 140610458367808 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 04:54:56.862602 140610458367808 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI0405 04:54:59.868999 140610458367808 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fe1e89553d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.717837 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fe1e89553d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc242ca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.935618 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc242ca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f4ee0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.935810 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f4ee0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e43825b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.935875 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e43825b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc0d0c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.935935 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc0d0c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0d0580>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.935982 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0d0580>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0d05b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936038 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0d05b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc0d0fa0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936089 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc0d0fa0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0c7250>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936137 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0c7250>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0c7460>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936202 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0c7460>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc0c7850>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936259 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fe1cc0c7850>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0c7be0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936323 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0c7be0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0c7b20>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936374 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0c7b20>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc05ee50>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936434 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc05ee50>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0b1c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936499 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0b1c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0b1190>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936549 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0b1190>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0b1130>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936603 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0b1130>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1e41c28e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936670 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1e41c28e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e40e1820>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936728 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e40e1820>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc36c190>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936782 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc36c190>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e44ca280>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936841 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e44ca280>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc050a60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936897 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc050a60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc126ca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.936977 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc126ca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc366c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937048 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc366c10>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc366d30>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937111 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc366d30>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1e429c130>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937165 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1e429c130>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e429c280>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937220 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1e429c280>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0683a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937279 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0683a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0688e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937337 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0688e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc396190>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937389 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc396190>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f9e50>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937447 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f9e50>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f9a60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937498 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f9a60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f9580>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937557 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f9580>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f9250>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937683 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f9250>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f9610>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937739 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f9610>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f0520>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937796 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f0520>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f05e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937856 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f05e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0d87f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937910 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0d87f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f13d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.937964 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f13d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f78e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.938015 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f78e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f7d30>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.938068 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f7d30>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f7fa0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.938119 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f7fa0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f7f40>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.938179 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f7f40>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f73a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.938233 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fe1cc0f73a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f72e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW0405 04:55:01.938288 140610458367808 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fe1cc0f72e0>, because it is not built.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mW0405 04:55:15.674380 140610458367808 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI0405 04:55:20.652599 140610458367808 builder_impl.py:797] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI0405 04:55:21.775639 140610458367808 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2023-04-05 04:55:23,233 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-04-05 04:55:39 Uploading - Uploading generated training model\n",
      "2023-04-05 04:55:39 Completed - Training job completed\n",
      "Training seconds: 4054\n",
      "Billable seconds: 4054\n"
     ]
    }
   ],
   "source": [
    "history = estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the intial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the writeup.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your writeup), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17284a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a00525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b3f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
